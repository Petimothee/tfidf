{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3079\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3080\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'summary'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-b46d0e747e63>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     67\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mcompute_tf_idf_document\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midf\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mterm_freq\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 69\u001B[0;31m \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'summary'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     70\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3022\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3023\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3024\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3025\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3080\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3082\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3084\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(\"./ASRS_data.csv\", sep=\"|\")\n",
    "\n",
    "def naif_regex_tokenize(text):\n",
    "    \"\"\"\n",
    "    This is a very naif way of tokenize a text. Just using the\n",
    "    regular expression \"[a-z]\" that will match any single word\n",
    "    in lowercase.\n",
    "    Returns a list with all the tokens.\n",
    "    \"\"\"\n",
    "    p = re.compile(\"[a-z]+\")\n",
    "    return p.findall(text.lower())\n",
    "\n",
    "def compute_tf(d):\n",
    "    \"\"\"\n",
    "    Compute the tf for a given document d.\n",
    "    The formula used is\n",
    "\n",
    "        tf(t, d) = 0.5 + 0.5 * (count(t, d)/max(count(t',d) for t' in d))\n",
    "\n",
    "    This prevents bias in longer documents.\n",
    "\n",
    "    count(t, d) represente le nombre de fois que apparait le mot dans ce document\n",
    "    max(count(t', d)) represente le mot qui apparait le plus dans ce document\n",
    "    \"\"\"\n",
    "    terms = pd.Series(naif_regex_tokenize(d))\n",
    "    term_counts = terms.value_counts()\n",
    "    max_tc = max(term_counts)\n",
    "    return 0.5 + 0.5 * (term_counts / max_tc)\n",
    "\n",
    "def compute_idf(D):\n",
    "    \"\"\"\n",
    "    The input D is a list of pandas.Series\n",
    "    having as each element, the term frequency\n",
    "    computed by the function compute_tf.\n",
    "    On divise le nombre de documents par le nombre de documents ou apparait chaque terme\n",
    "    \"\"\"\n",
    "    N = len(D)\n",
    "    all_terms = pd.concat(D)\n",
    "    nt = all_terms.index.value_counts() # The number of documents containing the term \"t\"\n",
    "    return np.log(N / nt)\n",
    "\n",
    "def compute_tf_idf_document(tf_document, idf):\n",
    "    \"\"\"Compute the tf-idf for each term in a document of the corpus\n",
    "\n",
    "    Keyword arguments:\n",
    "    tf_document -- list with the frequency of each term inside the document\n",
    "    idf -- the idf value for each term in the corpus\n",
    "    \"\"\"\n",
    "    return tf_document * np.array([idf[i] for i in tf_document.index])\n",
    "\n",
    "def compute_tf_idf_corpus(D):\n",
    "    \"\"\"Compute the tf-idf for each term in a corpus\n",
    "\n",
    "    Keyword arguments:\n",
    "    D -- pandas Series containing a collection of documents in text format\n",
    "\n",
    "    returns\n",
    "        list of pandas Series containing the tf-idf(t, d, D) for each term\n",
    "        inside each document of the corpus D\n",
    "    \"\"\"\n",
    "    term_freq = [compute_tf(d) for d in D]\n",
    "    idf = compute_idf(term_freq)\n",
    "    return [compute_tf_idf_document(d, idf) for d in term_freq]\n",
    "\n",
    "s = data['summary'][0]\n",
    "print(s)\n",
    "\n",
    "D1 = data['summary'][:10]\n",
    "\n",
    "tf_idf = compute_tf_idf_corpus(data.loc[:, \"summary\"])\n",
    "\n",
    "tf_idf[1]\n",
    "\n",
    "print(data[\"summary\"][1])\n",
    "\n",
    "tf_idf = np.array(tf_idf)\n",
    "\n",
    "\n",
    "\n",
    "def distance(v1, v2):\n",
    "    \"\"\"\n",
    "    Compute the distance between v1 and v2\n",
    "    v1 and v2 are numpy arrays\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((v1-v2)**2))\n",
    "\n",
    "def assign(vectors, centers):\n",
    "    \"\"\"\n",
    "    assign each vector to the closest center.\n",
    "    vectors is a numpy matrix. We want to assign each\n",
    "    row to the closest center.\n",
    "    centers is a numpy matrix. Each row has a center\n",
    "\n",
    "    returns a list of integers.\n",
    "    One value for each vector indicaing the closest center\n",
    "    \"\"\"\n",
    "    groups = np.zeros(vectors.shape[0])\n",
    "    for i in range(len(groups)):\n",
    "        groups[i] = np.argmin(np.apply_along_axis(distance, 1, centers, vectors[i]))\n",
    "    return groups\n",
    "\n",
    "def compute_centers(vectors, groups):\n",
    "    \"\"\"\n",
    "    Compute the centers for each group of\n",
    "    vectors\n",
    "    vectors is a numpy matrix\n",
    "    groups is a list containing the assignments\n",
    "    of the vectors\n",
    "    \"\"\"\n",
    "    new_centers = np.zeros([int(max(groups)) + 1, vectors.shape[1]])\n",
    "    for i in range(int(max(groups)) + 1):\n",
    "        ix = np.where(groups==i)[0]\n",
    "        grp_members = vectors[ix, :]\n",
    "        new_centers[i] = grp_members.mean(0)\n",
    "    return new_centers\n",
    "\n",
    "def choose_first_centers(vectors, k):\n",
    "    \"\"\"\n",
    "    Select the first k centers for the beginning of the\n",
    "    k-means algorithm\n",
    "    \"\"\"\n",
    "    ix = np.arange(0, vectors.shape[0])\n",
    "    np.random.shuffle(ix)\n",
    "    return vectors[ix[:k], :]\n",
    "\n",
    "def kmeans(vectors, k, max_iterations = 500):\n",
    "    \"\"\"\n",
    "    Naive implementation of k-means algorithm\n",
    "    \"\"\"\n",
    "    centers_list = []\n",
    "    centers = choose_first_centers(vectors, k)\n",
    "    centers_list.append(centers)\n",
    "    groups = assign(vectors, centers)\n",
    "    new_centers = compute_centers(vectors, groups)\n",
    "    centers_list.append(new_centers)\n",
    "    nb_iter = 0\n",
    "    while (np.sum(np.abs(centers - new_centers)) > 0) or (nb_iter > max_iterations):\n",
    "        centers = np.copy(new_centers)\n",
    "        groups = assign(vectors, centers)\n",
    "        new_centers = compute_centers(vectors, groups)\n",
    "        centers_list.append(new_centers)\n",
    "        nb_iter += 1\n",
    "    return new_centers, centers_list\n",
    "\n",
    "c, c_list = kmeans(vectors, 5)\n",
    "\n",
    "v1 = np.random.random([100, 2])-[2, 0]\n",
    "v2 = np.random.random([100, 2])+[2, 0]\n",
    "v3 = np.random.random([100, 2])-[0, 2]\n",
    "v4 = np.random.random([100, 2])+[0, 2]\n",
    "norm_v1 = np.linalg.norm(v1, axis=1)\n",
    "v1 = v1 / norm_v1[:, None]\n",
    "norm_v2 = np.linalg.norm(v2, axis=1)\n",
    "v2 = v2 / norm_v2[:, None]\n",
    "norm_v3 = np.linalg.norm(v3, axis=1)\n",
    "v3 = v3 / norm_v3[:, None]\n",
    "norm_v4 = np.linalg.norm(v4, axis=1)\n",
    "v4 = v4 / norm_v4[:, None]\n",
    "vectors = np.concatenate([v1, v2, v3, v4])\n",
    "\n",
    "df = pd.DataFrame({})\n",
    "for i in range(len(centers_list)):\n",
    "    v = {\"x\":vectors[:, 0], \"y\":vectors[:, 1], \"p_type\":[\"data_point\"]*vectors.shape[0],\n",
    "    \"iteration\":[i]*vectors.shape[0]}\n",
    "    df = pd.concat([df, pd.DataFrame(v)])\n",
    "    c = {\"x\":centers_list[i][:, 0], \"y\":centers_list[i][:, 1], \"p_type\":[\"center\"]*centers_list[0].shape[0],\n",
    "    \"iteration\":[i]*centers_list[0].shape[0]}\n",
    "    df = pd.concat([df, pd.DataFrame(c)])\n",
    "\n",
    "px.scatter(df, x=\"x\", y=\"y\", animation_frame=\"iteration\", color=\"p_type\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}